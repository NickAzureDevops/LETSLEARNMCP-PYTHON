paper_id,title,authors,abstract,url,published_date,research_field,keywords,downloads,likes,added_date
1906.05714,A Multiscale Visualization of Attention in the Transformer Model,Jesse Vig,"The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.",https://hf.co/papers/1906.05714,2019-06-12,machine_learning,"Transformer, attention, visualization, BERT, GPT-2",2500,2,2025-07-12T16:35:12.572069
2401.11673,MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo,"Chenjie Cao, Xinlin Ren, Yanwei Fu","Recent advancements in learning-based Multi-View Stereo (MVS) methods have prominently featured transformer-based models with attention mechanisms. However, existing approaches have not thoroughly investigated the profound influence of transformers on different MVS modules, resulting in limited depth estimation capabilities. In this paper, we introduce MVSFormer++, a method that prudently maximizes the inherent characteristics of attention to enhance various components of the MVS pipeline.",https://hf.co/papers/2401.11673,2024-01-22,computer_vision,"transformer, attention mechanisms, multi-view stereo, depth estimation",1800,0,2025-07-12T16:35:12.572103
2502.18277,Self-Adjust Softmax,"Chuanyang Zheng, Yihang Gao, Guoxuan Chen","The softmax function is crucial in Transformer attention, which normalizes each row of the attention scores with summation to one, achieving superior performances over other alternative functions. However, the softmax function can face a gradient vanishing issue when some elements of the attention scores approach extreme values, such as probabilities close to one or zero. In this paper, we propose Self-Adjust Softmax (SA-Softmax) to address this issue.",https://hf.co/papers/2502.18277,2025-02-25,machine_learning,"softmax, transformer attention, gradient vanishing, SA-Softmax",950,0,2025-07-12T16:35:12.572115
2103.14625,Dodrio: Exploring Transformer Models with Interactive Visualization,"Zijie J. Wang, Robert Turko, Duen Horng Chau","Why do large pre-trained transformer-based models perform so well across a wide variety of NLP tasks? Recent research suggests the key may lie in multi-headed attention mechanism's ability to learn and represent linguistic information. Understanding how these models represent both syntactic and semantic knowledge is vital to investigate why they succeed and fail, what they have learned, and how they can improve. We present Dodrio, an open-source interactive visualization tool to help NLP researchers and practitioners analyze attention mechanisms in transformer-based models with linguistic knowledge.",https://hf.co/papers/2103.14625,2021-03-26,natural_language_processing,"transformer, attention visualization, linguistic knowledge, NLP",3200,0,2025-07-12T16:35:12.572166
2408.05710,Efficient Diffusion Transformer with Step-wise Dynamic Attention Mediators,"Yifan Pu, Zhuofan Xia, Jiayi Guo","This paper identifies significant redundancy in the query-key interactions within self-attention mechanisms of diffusion transformer models, particularly during the early stages of denoising diffusion steps. In response to this observation, we present a novel diffusion transformer framework incorporating an additional set of mediator tokens to engage with queries and keys separately.",https://hf.co/papers/2408.05710,2024-08-11,machine_learning,"diffusion transformer, self-attention, mediator tokens, denoising",1500,2,2025-07-12T16:35:12.572189
2409.03752,Attention Heads of Large Language Models: A Survey,"Zifan Zheng, Yezhaohui Wang, Yuxin Huang, Shichao Song, Bo Tang, Feiyu Xiong, Zhiyu Li","Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in various tasks but remain largely as black-box systems. Consequently, their development relies heavily on data-driven approaches, limiting performance enhancement through changes in internal architecture and reasoning pathways. As a result, many researchers have begun exploring the potential internal mechanisms of LLMs, aiming to identify the essence of their reasoning bottlenecks, with most studies focusing on attention heads. Our survey aims to shed light on the internal reasoning processes of LLMs by concentrating on the interpretability and underlying mechanisms of attention heads.",https://hf.co/papers/2409.03752,2024-09-05,machine_learning,"Large Language Models, LLMs, attention heads, Knowledge Recalling, In-Context Identification, Latent Reasoning, Expression Preparation",0,92,2025-07-13T22:27:26.256132
1706.03762,Attention Is All You Need,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin","The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.",https://hf.co/papers/1706.03762,2017-06-12,machine_learning,"recurrent neural networks, convolutional neural networks, encoder-decoder configuration, attention mechanism, Transformer, BLEU score",0,69,2025-07-13T22:27:26.256158
2410.13276,SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs,"Yizhao Gao, Zhichen Zeng, Dayou Du, Shijie Cao, Hayden Kwok-Hay So, Ting Cao, Fan Yang, Mao Yang","Attention is the cornerstone of modern Large Language Models (LLMs). Yet its quadratic complexity limits the efficiency and scalability of LLMs, especially for those with a long-context window. A promising approach addressing this limitation is to leverage the sparsity in attention. However, existing sparsity-based solutions predominantly rely on predefined patterns or heuristics to approximate sparsity. This practice falls short to fully capture the dynamic nature of attention sparsity in language-based tasks. This paper argues that attention sparsity should be learned rather than predefined.",https://hf.co/papers/2410.13276,2024-10-17,machine_learning,"attention, Large Language Models, LLMs, quadratic complexity, sparsity, attention sparsity, SeerAttention",0,30,2025-07-13T22:27:26.256172
